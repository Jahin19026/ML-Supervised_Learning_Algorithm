{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94d3a51-15eb-442d-8ec4-d2f1a28aa6f4",
   "metadata": {},
   "source": [
    "**<span style=\"color: purple; font-size: 30px;\">Fake or Real News Detection</span>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b98cd-eef9-4aa4-b399-aa0884101653",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "I applied two common text vectorization techniques for news classification:\n",
    "\n",
    "1. **Bag-of-Words (Unigram / “Bag 1”)**  \n",
    "   - Converted each news article into a vector of word counts (after cleaning, lowercasing, and removing stopwords).  \n",
    "   - This captures the frequency of words but does not consider their relative importance across documents.\n",
    "\n",
    "2. **TF-IDF (Term Frequency – Inverse Document Frequency)**  \n",
    "   - Similar to Bag-of-Words, but assigns higher weight to words that are frequent in a document but rare across the whole dataset.  \n",
    "   - This helps to reduce the influence of very common words (e.g., *said*, *news*) that don’t carry much meaning for classification.\n",
    "\n",
    "Both representations were used with the **Multinomial Naive Bayes (NB)** classifier.  \n",
    "The dataset was split into 80% for training and 20% for testing.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc55ab-f558-4478-b4ed-983b2c078a01",
   "metadata": {},
   "source": [
    "**<h2 style =\"font size:20px;\">Approach: 1</h2>**\n",
    "\n",
    "**combined title + text into a single content column**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b536108-6ab9-4ca1-9a41-f6a42618167c",
   "metadata": {},
   "source": [
    "**Load and Quick Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f6a1ea-8421-4b31-86d7-ef48b551a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory\n",
    "import os\n",
    "os.chdir('I:\\Data Science and Machine Learning\\Python\\Python with Jupiter Notebook\\Class 42 Naïve Bayse Classifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1751221-6115-443b-937d-73607ef7ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'text', 'label'], dtype='object')\n",
      "(6335, 4)\n",
      "label\n",
      "REAL    3171\n",
      "FAKE    3164\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Assignment_Data_fake_or_real_news - Assignment_Data_fake_or_real_news.csv')\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ad5bd-0f54-49b3-a4bc-4f267e040fad",
   "metadata": {},
   "source": [
    "**Create a single text field, handle missing values, drop unused columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c816d3c0-de1c-45f4-bd8f-10a39e679308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine title + text\n",
    "df['title'] = df['title'].fillna('')\n",
    "df['text'] = df['text'].fillna('')\n",
    "df['content'] = (df['title']+ ' ' + df['text']).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf9f2ca-f3a8-44ae-828e-9dd7c557f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with empty content and id, title, text\n",
    "df = df[df['content'].str.strip() != '']\n",
    "df = df.drop(columns = ['id', 'title', 'text'], errors ='ignor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf23db92-a9c2-47e3-9dfb-04923de21228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'content'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>REAL</td>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>REAL</td>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>REAL</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0     FAKE  You Can Smell Hillary’s Fear Daniel Greenfield...\n",
       "1     FAKE  Watch The Exact Moment Paul Ryan Committed Pol...\n",
       "2     REAL  Kerry to go to Paris in gesture of sympathy U....\n",
       "3     FAKE  Bernie supporters on Twitter erupt in anger ag...\n",
       "4     REAL  The Battle of New York: Why This Primary Matte...\n",
       "...    ...                                                ...\n",
       "6330  REAL  State Department says it can't find emails fro...\n",
       "6331  FAKE  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "6332  FAKE  Anti-Trump Protesters Are Tools of the Oligarc...\n",
       "6333  REAL  In Ethiopia, Obama seeks progress on peace, se...\n",
       "6334  REAL  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[6335 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f34a3e-f986-478f-a35b-5a5b97d72fcb",
   "metadata": {},
   "source": [
    "**Basic Cleaning/ Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a057c669-1826-47fd-a794-ea9a4a3c44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', ' ', s)   # remove urls\n",
    "    s = re.sub(r'<[^>]+>', ' ', s)            # html tags\n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)        # keep alphanumeric\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "df['clean'] = df['content'].apply(clean_text)\n",
    "df['y'] = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d8bc8a-29aa-4c30-a8a5-707cf4263d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471     america is already strong obama continues demo...\n",
       " 4825    podesta relative earned six figure fees lobbyi...\n",
       " 6166    bitcoin soars as china launches crackdown on w...\n",
       " 4886    nanny in jail after force feeding baby to deat...\n",
       " 2646    lavrov schools european diplomats in logic usi...\n",
       "                               ...                        \n",
       " 90      exclusive gop campaigns plot revolt against rn...\n",
       " 917     who s winning indiana it s anybody s guess the...\n",
       " 1101    three ways to recharge your energy using cryst...\n",
       " 1845    principal institutes ban after students wear c...\n",
       " 698     michael moore joe blow will vote trump as ulti...\n",
       " Name: clean, Length: 5068, dtype: object,\n",
       " 1707    israel votes netanyahu s last ditch vow to his...\n",
       " 1926    the source of our rage the ruling elite is pro...\n",
       " 2674    should birthright citizenship be abolished roo...\n",
       " 2597    study running linked to extended lifespan and ...\n",
       " 4602    10 things trump could but probably won t chang...\n",
       "                               ...                        \n",
       " 3049    baltimore race and matters of perception comme...\n",
       " 5609    if you really want to save energy at home forg...\n",
       " 1874    this election is an unpopularity contest for t...\n",
       " 4439    taking calcium supplements causes brain lesion...\n",
       " 1805    clinton makes history declares win in democrat...\n",
       " Name: clean, Length: 1267, dtype: object,\n",
       " 471     REAL\n",
       " 4825    FAKE\n",
       " 6166    FAKE\n",
       " 4886    FAKE\n",
       " 2646    FAKE\n",
       "         ... \n",
       " 90      REAL\n",
       " 917     REAL\n",
       " 1101    FAKE\n",
       " 1845    FAKE\n",
       " 698     FAKE\n",
       " Name: y, Length: 5068, dtype: object,\n",
       " 1707    REAL\n",
       " 1926    FAKE\n",
       " 2674    REAL\n",
       " 2597    FAKE\n",
       " 4602    REAL\n",
       "         ... \n",
       " 3049    REAL\n",
       " 5609    REAL\n",
       " 1874    REAL\n",
       " 4439    FAKE\n",
       " 1805    REAL\n",
       " Name: y, Length: 1267, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df['clean']\n",
    "y = df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =0.2, stratify = y, random_state = 42)\n",
    "x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb95550f-a42f-4c9f-9758-3b4c884f7f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5068,)\n",
      "(1267,)\n",
      "(5068,)\n",
      "(1267,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e7097-4f9c-407c-a2b1-17c9ed6ebf2b",
   "metadata": {},
   "source": [
    "**Vectorization — Bag-of-Words (CountVectorizer, unigram)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b65b934-aec1-4c5e-b1e9-2b00c11e19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words = 'english', min_df = 5, max_df = 0.95, ngram_range = (1,1))\n",
    "x_train_cv = cv.fit_transform(x_train)\n",
    "x_test_cv  = cv.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eaf62e-b969-45b2-8018-4f1fa2379aa6",
   "metadata": {},
   "source": [
    "- Stop words are frequent words like \"the\", \"is\", \"in\", \"on\", \"and\", \"of\", \"to\". -\n",
    "- min_df removes very rare tokens (reduces noise). -\n",
    "- max_df removes tokens that appear in too many docs (non-informative). -\n",
    "- ngram_range=(1,1) = unigram (bag 1). You can later try (1,2) to add bigrams. -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeede40-1b39-4c04-bef3-ed505680a45d",
   "metadata": {},
   "source": [
    "**Vectorization — TF-IDF** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19085185-506a-4923-aec6-a059427e6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(stop_words = 'english', min_df = 5, max_df = 0.95, ngram_range = (1,1))\n",
    "x_train_tf = tf.fit_transform(x_train)\n",
    "x_test_tf = tf.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f18029-ab41-4b18-a86d-381b3501de38",
   "metadata": {},
   "source": [
    "**What is MultinomialNB?**\n",
    "\n",
    "- It’s the Multinomial Naive Bayes classifier. -\n",
    "- Commonly used for text classification (spam detection, fake news, sentiment, etc.). -\n",
    "- It assumes features are counts or frequencies (like word counts from Bag-of-Words or TF-IDF).-\n",
    "- The model estimates the probability of a document belonging to each class based on word frequencies. -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f46f01-f7e5-4599-acf9-0ff85e51d79c",
   "metadata": {},
   "source": [
    "**What does alpha=1.0 mean?**\n",
    "\n",
    "- alpha = 1.0 → Laplace smoothing (adds 1 to all counts).This prevents zero probabilities and makes the model more robust. - \n",
    "- alpha = 0 → no smoothing (risky, not recommended). -\n",
    "- alpha < 1 → lighter smoothing.-\n",
    "- alpha > 1 → heavier smoothing (flattens probability distribution more).-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc3275b5-65aa-4761-ba8a-d99d86ac8b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Accuracy: 0.8784530386740331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.88      0.88      0.88       633\n",
      "        REAL       0.88      0.88      0.88       634\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.88      0.88      0.88      1267\n",
      "weighted avg       0.88      0.88      0.88      1267\n",
      "\n",
      "[[558  75]\n",
      " [ 79 555]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#BoW (unigram) is the classic baseline (what we called “bag 1”).\n",
    "#Bag-of-words baseline\n",
    "nb_cv = MultinomialNB(alpha =1.0)\n",
    "nb_cv.fit(x_train_cv, y_train)\n",
    "y_pred_cv = nb_cv.predict(x_test_cv)\n",
    "print(\"BoW Accuracy:\", accuracy_score(y_test, y_pred_cv))\n",
    "print(classification_report(y_test, y_pred_cv))\n",
    "print(confusion_matrix(y_test, y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f51bfc-6769-4584-8a7f-de67540a6436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy: 0.877663772691397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.92      0.83      0.87       633\n",
      "        REAL       0.84      0.93      0.88       634\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.88      0.88      0.88      1267\n",
      "weighted avg       0.88      0.88      0.88      1267\n",
      "\n",
      "[[523 110]\n",
      " [ 45 589]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF baseline\n",
    "nb_tf = MultinomialNB(alpha =1.0)\n",
    "nb_tf.fit(x_train_tf, y_train)\n",
    "y_pred_tf = nb_tf.predict(x_test_tf)\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred_tf))\n",
    "print(classification_report(y_test, y_pred_tf))\n",
    "print(confusion_matrix(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbf4e1-1e0e-400b-8b85-c5ec19856721",
   "metadata": {},
   "source": [
    "\n",
    "## Results\n",
    "\n",
    "- **Bag-of-Words + NB:** Accuracy ≈ **87.8%**  \n",
    "- **TF-IDF + NB:** Accuracy ≈ **87.7%**\n",
    "\n",
    "Both approaches performed almost equally well, with Bag-of-Words giving a very slight edge in accuracy.  \n",
    "TF-IDF, however, provided a better balance between **precision and recall** across the two classes (FAKE vs REAL).\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Using **Bag-of-Words** and **TF-IDF**, we compared classification performance.  \n",
    "Accuracy was similar in both methods, showing that for this dataset, either representation works effectively with Naive Bayes.  \n",
    "\n",
    "- Bag-of-Words gave slightly higher **accuracy**.  \n",
    "- TF-IDF offered more **balanced performance** across classes.\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6f39f-ad3e-4673-adf8-bf53a086a13d",
   "metadata": {},
   "source": [
    "**<h2 style =\"font size:20px;\">Approach: 2</h2>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1f96d-4875-43c3-9ad4-ba5e0d965b04",
   "metadata": {},
   "source": [
    "**Using only one column (e.g., text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "939024e8-f262-49ea-9102-43bf7ef5bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "data = pd.read_csv(\"Assignment_Data_fake_or_real_news - Assignment_Data_fake_or_real_news.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f037840-11ae-4227-bd2a-e65d7a5ccc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "Y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c9fcef8-4395-468c-a5b5-8c884f8ab1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing values (replace NaN with empty string)\n",
    "X = X.fillna(\"\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "179e19d8-08b5-461b-b06c-27d873752d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size =0.2, random_state = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec493eac-3192-43f2-971f-981daea8748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag-of-Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words = 'english', min_df = 5, max_df = 0.95, ngram_range = (1, 2)) #unigram + bigrams\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8faf70b-2e40-46e2-95e1-c1e1879d4ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5068, 57373)\n",
      "Test shape: (1267, 57373)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of matrices (just to check)\n",
    "print(\"Train shape:\", X_train_cv.shape)\n",
    "print(\"Test shape:\", X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d88bdc4-f062-4b6a-8a7b-ce172b4fcc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Accuracy: 0.9234411996842936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.93      0.92      0.92       627\n",
      "        REAL       0.92      0.93      0.92       640\n",
      "\n",
      "    accuracy                           0.92      1267\n",
      "   macro avg       0.92      0.92      0.92      1267\n",
      "weighted avg       0.92      0.92      0.92      1267\n",
      "\n",
      "[[575  52]\n",
      " [ 45 595]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Bag-of-words baseline\n",
    "nb_cv = MultinomialNB(alpha =1.0)\n",
    "nb_cv.fit(X_train_cv, Y_train)\n",
    "Y_pred_cv = nb_cv.predict(X_test_cv)\n",
    "print(\"BoW Accuracy:\", accuracy_score(Y_test, Y_pred_cv))\n",
    "print(classification_report(Y_test, Y_pred_cv))\n",
    "print(confusion_matrix(Y_test, Y_pred_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb0684-b205-47ad-8ddd-78faf5f6e7f0",
   "metadata": {},
   "source": [
    "**Vectorization : TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ffe79b2-74c3-4659-8120-9bbc8afd2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(stop_words = 'english', min_df = 5, max_df = 0.95, ngram_range = (1,2))\n",
    "X_train_tf = tf.fit_transform(X_train)\n",
    "X_test_tf = tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "616f15c7-d4e6-4bd7-947b-1067fd661f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Accuracy: 0.9068666140489345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.96      0.85      0.90       627\n",
      "        REAL       0.87      0.96      0.91       640\n",
      "\n",
      "    accuracy                           0.91      1267\n",
      "   macro avg       0.91      0.91      0.91      1267\n",
      "weighted avg       0.91      0.91      0.91      1267\n",
      "\n",
      "[[533  94]\n",
      " [ 24 616]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF baseline\n",
    "nb_tf = MultinomialNB(alpha =1.0)\n",
    "nb_tf.fit(X_train_tf, Y_train)\n",
    "Y_pred_tf = nb_tf.predict(X_test_tf)\n",
    "print(\"TF-IDF Accuracy:\", accuracy_score(Y_test, Y_pred_tf))\n",
    "print(classification_report(Y_test, Y_pred_tf))\n",
    "print(confusion_matrix(Y_test, Y_pred_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28bd1d2-a7cc-45a6-b126-82a01c2eaba7",
   "metadata": {},
   "source": [
    "**<h2 style =\"font size:20px;\">Results and Findings</h2>**\n",
    "**Why Accuracy Improved with random_state=28 and ngram_range=(1,2)**\n",
    "**1. Changing random_state**\n",
    "\n",
    "- The train/test split depends on the random seed. -\n",
    "- Using random_state=28 instead of 42 created a different split of the data.-\n",
    "- Sometimes, the new split makes the test set easier (less ambiguous, better balanced), which leads to higher accuracy.-\n",
    "- ⚠️ This doesn’t mean the model itself is universally better — just that this split worked better.-\n",
    "- ✅ To get a more reliable estimate, researchers often use **cross-validation** instead of relying on one split.-\n",
    "\n",
    "\n",
    "**2. Changing ngram_range=(1,2) instead of (1,1)**\n",
    "\n",
    "- (1,1) → uses only unigrams (single words).-\n",
    "- (1,2) → uses unigrams + bigrams (word pairs).-\n",
    "- Bigrams capture context and phrases that single words can miss:**\"fake news\", \"breaking story\", \"white house\"**.-\n",
    "- These phrases often carry stronger signals in tasks like fake/real news detection.-\n",
    "- ✅ Adding bigrams usually improves accuracy because the model learns **patterns, not just words.**-\n",
    "\n",
    "\n",
    "\n",
    "**<h2 style =\"font size:20px;\">Conclusion</h2>**\n",
    "\n",
    "- BoW with bigrams: ~92.3% accuracy -\n",
    "- TF-IDF with bigrams: ~90.6% accuracy -\n",
    "- Both are better than unigram-only models. -\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
